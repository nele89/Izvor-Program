# auto_pipeline.py

import sys
import os
import time
from logs.logger import log
from utils.settings_handler import load_settings
from utils.converter_scheduler import convert_all_ticks
from ai.trainer import train_and_save_model
from backend.ai_analyzer import analyze_data
from utils.report_generator import generate_daily_report

def wait_for_download_threads(threads, timeout=900):
    """ÄŒeka da svi download threadovi zavrÅ¡e ili dok ne istekne timeout (sekunde)."""
    start = time.time()
    for t in threads:
        while t.is_alive():
            if time.time() - start > timeout:
                log.error("âŒ Download threadovi nisu zavrÅ¡ili na vreme (timeout).")
                return False
            time.sleep(1)
    return True

def run_pipeline():
    log.info("ğŸš¦ [AUTO-PIPELINE] PoÄetak automatizovanog procesa...")

    # 1. UÄitaj podeÅ¡avanja
    settings = load_settings()
    symbols = settings.get("dukascopy", {}).get("symbols", ["XAUUSD", "EURUSD", "USDJPY"])
    if isinstance(symbols, str):
        symbols = [s.strip() for s in symbols.split(",") if s.strip()]
    log.info(f"ğŸ“¥ Simboli za download: {symbols}")

    # 2. Download najnovijih podataka (samo CSV) â€” dobijamo thread listu
    log.info("â¬ Skidanje podataka sa Dukascopy...")
    from data.downloader.dukascopy_downloader import download_symbol, DEFAULT_FOLDER
    from datetime import datetime

    start_date = settings.get("dukascopy", {}).get("start_date", "2015-01-01T00:00:00")
    end_date = settings.get("dukascopy", {}).get("end_date", "2025-06-30T00:00:00")
    try:
        start_dt = datetime.fromisoformat(start_date)
        end_dt = datetime.fromisoformat(end_date)
    except Exception:
        from datetime import datetime as dtn
        start_dt = dtn(2015, 1, 1)
        end_dt = dtn.utcnow()

    threads = []
    for symbol in symbols:
        import threading
        t = threading.Thread(
            target=download_symbol,
            args=(symbol, start_dt, end_dt, DEFAULT_FOLDER, 0.2),
            daemon=True
        )
        t.start()
        threads.append(t)

    log.info("â³ ÄŒekam zavrÅ¡etak download procesa (svi threadovi)...")
    wait_for_download_threads(threads, timeout=1800)
    log.info("âœ… Download CSV fajlova kompletiran.")

    # 3. Konverzija CSV-ova u Å¾eljene timeframove
    log.info("ğŸ”„ PokreÄ‡em konverziju CSV tick podataka u M1/M5/H1...")
    convert_all_ticks()
    log.info("âœ… Konverzija podataka zavrÅ¡ena.")

    # 4. Treniranje AI modela na novim podacima
    log.info("ğŸ¤– PokreÄ‡em treniranje AI modela...")
    try:
        train_and_save_model()
        log.info("âœ… AI model uspeÅ¡no treniran na najnovijim podacima.")
    except Exception as e:
        log.error(f"âŒ Trening AI modela nije uspeo: {e}")

    # 5. Analiza podataka posle treniranja (opciono)
    try:
        log.info("ğŸ” PokreÄ‡em analizu podataka (AI analiza)...")
        analyze_data()
        log.info("âœ… Analiza podataka zavrÅ¡ena.")
    except Exception as e:
        log.error(f"âŒ Analiza podataka nije uspela: {e}")

    # 6. Generisanje izveÅ¡taja (opciono, moÅ¾eÅ¡ birati dnevni/nedeljni)
    try:
        log.info("ğŸ“ GeneriÅ¡em dnevni izveÅ¡taj...")
        today = time.strftime("%Y-%m-%d")
        generate_daily_report(today)
        log.info("âœ… Dnevni izveÅ¡taj uspeÅ¡no generisan.")
    except Exception as e:
        log.error(f"âŒ Generisanje dnevnog izveÅ¡taja nije uspelo: {e}")

    log.info("ğŸ [AUTO-PIPELINE] Automatizovani proces zavrÅ¡en.")

if __name__ == "__main__":
    run_pipeline()
